import datetime
import os
import hydra
from omegaconf import DictConfig, OmegaConf
from pytorch_lightning import seed_everything
from tqdm import tqdm
from hydra.utils import instantiate
import torch
from hydra import initialize, compose
import sys  # æ–°å¢å¯¼å…¥sysæ¨¡å—


class LogFileHandler:
    def __init__(self, file_path):
        self.file_path = file_path
        os.makedirs(os.path.dirname(file_path), exist_ok=True)

    def log(self, metrics):
        try:
            with open(self.file_path, "a") as f:
                timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                log_line = f"{timestamp} - " + ", ".join([f"{k}: {v}" for k, v in metrics.items()])
                f.write(log_line + "\n")
        except Exception as e:
            print(f"Error writing to log file: {e}")


@hydra.main(version_base=None, config_path="configs", config_name="gene_expansion_test_m")
def main(cfg: DictConfig):
    # æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦åœ¨å¾ªç¯æµ‹è¯•æ¨¡å¼ä¸‹
    test_names = [f"test{i}" for i in range(2, 8)]  # test1åˆ°test7
    seed = cfg.test.seed
    epoch = cfg.test.epoch
    result_path = cfg.test.result_path
    solver = cfg.test.solver

    all_results = {}  # å­˜å‚¨æ‰€æœ‰æµ‹è¯•ç»“æœ

    for test_name in test_names:
        print(f"æµ‹è¯•æ•°æ®é›†ä¸ºï¼š {test_name}")
        # åŠ¨æ€æ›´æ–°é…ç½®ä¸­çš„æµ‹è¯•é›†
        test_data_config = OmegaConf.load(f"{cfg.machine.work_dir}/configs/test/{test_name}.yaml")

        # ç›´æ¥è¦†ç›–æ•´ä¸ªèŠ‚ç‚¹
        OmegaConf.set_struct(cfg, False)
        cfg.test = test_data_config
        cfg.test.seed = seed
        cfg.test.epoch = epoch
        cfg.test.result_path = result_path
        cfg.test.solver = solver
        OmegaConf.set_struct(cfg, True)

        # ç¯å¢ƒè®¾ç½®ï¼ˆåŸä»£ç ä¿æŒä¸å˜ï¼‰
        os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
        os.environ['HF_MIRROR'] = 'https://hf-mirror.com'
        os.environ["HYDRA_FULL_ERROR"] = str(1)

        # åˆå§‹åŒ–Fabric
        fabric = instantiate(cfg.machine.fabric)
        fabric.launch()
        fabric.print(f"ğŸ å¼€å§‹æµ‹è¯• {test_name} (è®¾å¤‡: {fabric.device})")

        # è®¾ç½®éšæœºç§å­
        seed_everything(cfg.test.seed)

        # æ—¥å¿—åˆå§‹åŒ– - ä½¿ç”¨å½“å‰æµ‹è¯•é›†åç§°
        log_file = os.path.join("test", test_name, datetime.datetime.now().strftime("%m-%d-%H-%M-%S") + ".log")
        file_logger = None
        if fabric.is_global_zero:
            file_logger = LogFileHandler(log_file)
            fabric.print(f"ğŸ“ æ—¥å¿—ä¿å­˜åˆ° {log_file}")

        # å‡†å¤‡æµ‹è¯•æ•°æ®
        dataset = instantiate(cfg.test, _recursive_=False)
        test_loader = fabric.setup_dataloaders(dataset.test_dataloader())
        fabric.print(f"ğŸ“Š æµ‹è¯•é›†å¤§å°: {len(test_loader.dataset)} æ ·æœ¬")

        # æ„å»ºæ¨¡å‹
        model = instantiate(cfg.model)
        model = fabric.setup(model)
        model.scheduler = cfg.test.solver
        fabric.print(f"é‡‡æ ·æ–¹å¼: {model.scheduler}")

        # åŠ è½½æ£€æŸ¥ç‚¹
        target_epoch = cfg.test.epoch
        ckpt_path = f"epoch_{target_epoch}.ckpt"
        if not os.path.exists(ckpt_path):
            raise FileNotFoundError(f"æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {ckpt_path}")
        fabric.print(f"â¬‡ï¸ åŠ è½½æ£€æŸ¥ç‚¹: {ckpt_path}")
        fabric.load(ckpt_path, {"model": model})

        # è¿è¡Œæµ‹è¯•
        fabric.print("ğŸ” å¼€å§‹æ¨¡å‹è¯„ä¼°...")
        results = test(model, test_loader, fabric, cfg, file_logger)

        # ä¿å­˜å½“å‰æµ‹è¯•ç»“æœ
        all_results[test_name] = results
        fabric.print(f"\nâ­ {test_name} ç»“æœ:")
        for metric, value in results.items():
            fabric.print(f"  {metric.upper()}: {value:.6f}")

        # æ‰“å°å½“å‰ç´¯è®¡æ‰€æœ‰ç»“æœ
        fabric.print("\n" + "=" * 30 + " å½“å‰ç´¯è®¡ç»“æœ " + "=" * 30)
        for test_name, res in all_results.items():
            fabric.print(f"ğŸ”¬ {test_name}: " + ", ".join([f"{k}={v:.4f}" for k, v in res.items()]))
        fabric.print("=" * 70 + "\n")

        # æ¸…ç†èµ„æº
        del model, test_loader, dataset
        torch.cuda.empty_cache() if torch.cuda.is_available() else None

    # æœ€ç»ˆæŠ¥å‘Š
    fabric.print("\n" + "ğŸ”¥ğŸ”¥ğŸ”¥ æ‰€æœ‰æµ‹è¯•å®Œæˆ! æœ€ç»ˆç»“æœ ğŸ”¥ğŸ”¥ğŸ”¥")
    for test_name, res in all_results.items():
        fabric.print(f"ğŸ¯ {test_name}: " + ", ".join([f"{k}={v:.4f}" for k, v in res.items()]))


def test(model, test_loader, fabric, cfg, file_logger=None):
    model.eval()
    total_metrics = {}
    count = 0

    if fabric.is_global_zero:
        pbar = tqdm(total=len(test_loader), desc="Test: ", dynamic_ncols=True)
    else:
        pbar = None

    with torch.no_grad():
        for batch_idx, batch in enumerate(test_loader):

            if batch_idx > 100:
                break

            # æ¨¡å‹å‰å‘ä¼ æ’­
            metrics = model.validation_step(batch, batch_idx, fabric, stage="test", solver=cfg.test.solver)
            # ç´¯ç§¯æŒ‡æ ‡
            for k, v in metrics.items():
                if k not in total_metrics:
                    total_metrics[k] = 0.0
                total_metrics[k] += v

            count += 1

            # æ›´æ–°è¿›åº¦
            if pbar is not None:
                pbar.update(1)
                pbar.set_postfix({k: f"{v:.4f}" for k, v in metrics.items()})

            # è®°å½•æ‰¹æ¬¡ç»“æœ
            if file_logger is not None and fabric.is_global_zero:
                log_data = {f"Test_{k}": v for k, v in metrics.items()}
                log_data["Batch"] = batch_idx
                file_logger.log(log_data)

    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    avg_metrics = {k: v / count for k, v in total_metrics.items()}

    if pbar is not None:
        pbar.close()

    return avg_metrics

# ä¿®æ”¹å…¥å£ç‚¹ä»¥æ”¯æŒå¾ªç¯æ¨¡å¼
if __name__ == "__main__":
    main()